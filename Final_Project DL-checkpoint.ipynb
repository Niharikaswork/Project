{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573d108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822ed360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"C:\\\\Users\\\\Akash\\Desktop\\\\UD SculptureDataset\\\\Train\"\n",
    "test_path=\"C:\\\\Users\\\\Akash\\Desktop\\\\UD SculptureDataset\\\\Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37fef956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHRIST THE TEACHER',\n",
       " 'DANTE',\n",
       " 'HAIL MARY',\n",
       " 'HONOR ROLL',\n",
       " 'JANE AUSTEN',\n",
       " 'JOHN F. KENNEDY',\n",
       " 'KAPPA ALPHA PSI',\n",
       " 'KNIGHT BY BROTHER MEL',\n",
       " 'LADY OF THE PINES',\n",
       " 'MARTIN LUTHER KING JR',\n",
       " 'MARY LOUISA',\n",
       " 'MARY OF CANA',\n",
       " 'MARY, SEAT OF WISDOM',\n",
       " 'MOSES MAIMONIDES',\n",
       " 'OMEGA POINT',\n",
       " 'RED CUBE',\n",
       " 'SERENITY PINES',\n",
       " 'THE HOLY FAMILY',\n",
       " 'THOMAS EQUINAS',\n",
       " 'THRONE BY BROTHER MEL',\n",
       " 'TRUSTING IN DREAMS',\n",
       " 'WILLIAM JOSEPH CHAMINADE',\n",
       " 'WILLIAM SHAKESPEARE',\n",
       " 'WOLFGANG AMADEUS MOZART']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9361b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                30744     \n",
      "=================================================================\n",
      "Total params: 11,868,680\n",
      "Trainable params: 30,744\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import regularizers\n",
    "base_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/lite4/feature-vector/2\",\n",
    "                      input_shape=(244,244)+(3,),\n",
    "                      trainable=False)\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    " tf.keras.layers.Dense(24, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3179e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    " loss='categorical_crossentropy',\n",
    " metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0bd254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3615 images belonging to 24 classes.\n",
      "Found 385 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255.,width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True )\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,batch_size=20,class_mode='categorical',target_size=(224, 224))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(test_path,batch_size=20,class_mode='categorical',target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47646d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "181/181 [==============================] - 634s 3s/step - loss: 0.8521 - acc: 0.8028 - val_loss: 1.9036 - val_acc: 0.7750\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 625s 3s/step - loss: 0.1773 - acc: 0.9676 - val_loss: 1.6508 - val_acc: 0.8350\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 623s 3s/step - loss: 0.1086 - acc: 0.9848 - val_loss: 1.9912 - val_acc: 0.8100\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 626s 3s/step - loss: 0.0744 - acc: 0.9887 - val_loss: 1.7130 - val_acc: 0.8450\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 625s 3s/step - loss: 0.0577 - acc: 0.9928 - val_loss: 2.1009 - val_acc: 0.8150\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 624s 3s/step - loss: 0.0418 - acc: 0.9947 - val_loss: 1.9584 - val_acc: 0.8350\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 620s 3s/step - loss: 0.0381 - acc: 0.9942 - val_loss: 2.3169 - val_acc: 0.8200\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 623s 3s/step - loss: 0.0298 - acc: 0.9953 - val_loss: 2.5501 - val_acc: 0.8050\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 696s 4s/step - loss: 0.0261 - acc: 0.9961 - val_loss: 2.4793 - val_acc: 0.8150\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 795s 4s/step - loss: 0.0221 - acc: 0.9978 - val_loss: 2.4868 - val_acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    " validation_data=validation_generator,\n",
    " epochs=10,\n",
    " validation_steps=10,\n",
    " verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7767690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Saved_Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Saved_Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_path = \"D:\\\\Saved_Model1\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a111165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'{model_path}/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2896f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 05:42:51.084165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-28 05:42:51.084224: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-28 05:42:57.840619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2021-11-28 05:42:57.840655: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-28 05:42:57.846304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: LAPTOP-6PJLEEGB\n",
      "2021-11-28 05:42:57.846367: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: LAPTOP-6PJLEEGB\n",
      "2021-11-28 05:42:57.846721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "C:\\Users\\Akash\\anaconda3\\lib\\runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-11-28 05:42:57,847 - INFO - Using tensorflow=2.6.0, onnx=1.10.2, tf2onnx=1.9.3/1190aa\n",
      "2021-11-28 05:42:57,847 - INFO - Using opset <onnx, 11>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2021-11-28 05:42:58,625 - INFO - Optimizing ONNX model\n",
      "2021-11-28 05:43:01,798 - INFO - After optimization: Const -151 (339->188), GlobalAveragePool +1 (0->1), Identity -1 (1->0), ReduceMean -1 (1->0), Reshape -30 (30->0), Squeeze +1 (0->1), Transpose -364 (365->1)\n",
      "2021-11-28 05:43:01,916 - INFO - \n",
      "2021-11-28 05:43:01,916 - INFO - Successfully converted TensorFlow model D:\\\\Saved_Model\\\\model.tflite to ONNX\n",
      "2021-11-28 05:43:01,916 - INFO - Model inputs: ['serving_default_keras_layer_input:0']\n",
      "2021-11-28 05:43:01,916 - INFO - Model outputs: ['StatefulPartitionedCall:0']\n",
      "2021-11-28 05:43:01,916 - INFO - ONNX model is saved at D:\\\\Saved_Model\\\\model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --opset 11 --tflite \"D:\\\\Saved_Model1\\\\model.tflite\" --output \"D:\\\\Saved_Model1\\\\model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546423e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
